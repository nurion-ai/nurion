# Solstice Streaming Framework - Project Overview

## What is Solstice Streaming?

A Ray-based distributed streaming processing framework inspired by the fusionflow blueprint, featuring exactly-once semantics, elastic scaling, and fault tolerance.

## Key Characteristics

- **Hybrid Model**: Batch + Streaming execution
- **Exactly-Once**: Checkpoint-based recovery
- **Elastic**: Dynamic worker scaling
- **Fault-Tolerant**: Automatic recovery from failures
- **Remote State**: S3/DFS/HDFS backends
- **Zero Dependencies**: No Kafka, RocksDB, or ZooKeeper

## Directory Structure

```
solstice/
â”œâ”€â”€ solstice/              # Framework implementation
â”‚   â”œâ”€â”€ core/              # Job, Stage, Operator abstractions
â”‚   â”œâ”€â”€ actors/            # Ray actors (Meta Service, Stage Master, Worker)
â”‚   â”œâ”€â”€ state/             # State management & checkpointing
â”‚   â”œâ”€â”€ operators/         # Built-in operators
â”‚   â””â”€â”€ main.py            # CLI entry point
â”‚
â”œâ”€â”€ workflows/             # Example workflows
â”‚   â”œâ”€â”€ simple_etl.py      # Basic ETL pipeline
â”‚   â””â”€â”€ video_processing.py # Video processing pipeline
â”‚
â”œâ”€â”€ configs/               # Configuration files
â”‚   â”œâ”€â”€ simple_etl.yaml
â”‚   â””â”€â”€ video_processing.yaml
â”‚
â””â”€â”€ Documentation files    # See INDEX.md for full list
```

## Core Concepts

### 1. Job
A complete processing pipeline with a DAG of stages.

```python
job = Job(job_id='my_pipeline')
```

### 2. Stage
A processing step with an operator and parallelism configuration.

```python
Stage('transform', MapOperator, {...}, parallelism=4)
Stage('scale', MapOperator, {...}, parallelism=(2, 10))
```

### 3. Operator
The logic that processes data.

```python
class MyOperator(Operator):
    def process(self, record):
        # Transform record
        return [transformed_record]
```

### 4. State Backend
Where checkpoints are stored.

```python
LocalStateBackend('/tmp/checkpoints')  # Testing
S3StateBackend('my-bucket')            # Production
```

## Built-in Operators

| Operator | Type | Description |
|----------|------|-------------|
| LanceTableSource | Source | Read from Lance tables |
| FileSource | Source | Read from JSON/Parquet/CSV |
| MapOperator | Transform | 1-to-1 transformation |
| FlatMapOperator | Transform | 1-to-N transformation |
| FilterOperator | Transform | Filter records |
| KeyByOperator | Transform | Extract keys |
| FileSink | Sink | Write to files |
| LanceSink | Sink | Write to Lance |
| PrintSink | Sink | Print to stdout |

## Parallelism Modes

### Fixed Parallelism
```python
parallelism=4  # Always 4 workers
```

Use for:
- Source/Sink operations
- Predictable workloads
- When you want exact resource control

### Auto-Scaling Parallelism
```python
parallelism=(2, 10)  # Scale between 2 and 10 workers
```

Use for:
- Variable workloads
- CPU/GPU intensive operations
- When you want optimal resource utilization

## Usage Patterns

### Pattern 1: Simple ETL
```
Source â†’ Transform â†’ Filter â†’ Sink
```

### Pattern 2: Fan-Out
```
Source â†’ FlatMap â†’ [Multiple Workers] â†’ Aggregate â†’ Sink
```

### Pattern 3: Complex Pipeline
```
Source â†’ Preprocess â†’ Classify â†’ Filter â†’ 
  Detect â†’ Extract â†’ PostProcess â†’ Sink
```

## Running the Framework

### Quickstart
```bash
cd /path/to/nurion/solstice
python quickstart.py
```

### With Configuration
```bash
python -m solstice.main \
  --config configs/simple_etl.yaml \
  --workflow workflows.simple_etl \
  --job-id my_job
```

### On Ray Cluster
```bash
python -m solstice.main \
  --config configs/video_processing.yaml \
  --workflow workflows.video_processing \
  --ray-address ray://head-node:10001
```

## Checkpointing

### Automatic
```python
job = Job(
    job_id='my_job',
    checkpoint_interval_secs=300,      # Every 5 minutes
    checkpoint_interval_records=10000,  # Or 10k records
)
```

### Manual
```python
runner = job.create_ray_runner()
runner.initialize()
checkpoint_id = runner.trigger_checkpoint()
runner.restore_from_checkpoint(checkpoint_id)
```

## Implementation Stats

- **Python Files**: 22 core + 3 workflows = 25 total
- **Documentation**: 12 markdown files
- **Examples**: 3 (quickstart + 2 workflows)
- **Configurations**: 2 YAML files
- **Lines of Code**: ~4,000+

## Architecture Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 4: User API                       â”‚
â”‚ (Job, Stage, Operator)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 3: Coordination                   â”‚
â”‚ (Meta Service, Global State Master)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 2: Execution                      â”‚
â”‚ (Stage Master, Workers)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 1: State Management               â”‚
â”‚ (State Manager, Checkpoint Coordinator) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 0: Storage                        â”‚
â”‚ (State Backend: S3/DFS/Local)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Feature Comparison

| Feature | Solstice | Flink | Spark Streaming |
|---------|----------|-------|-----------------|
| Exactly-Once | âœ… | âœ… | âœ… |
| Dynamic Scaling | âœ… | Limited | Limited |
| No External Deps | âœ… | âŒ | âŒ |
| Lance Integration | âœ… | âŒ | âŒ |
| Python-First | âœ… | âŒ | âœ… |
| State Backend | S3/DFS | RocksDB | HDFS |

## Next Steps

1. **Read**: [START_HERE.md](START_HERE.md) or [GETTING_STARTED.md](GETTING_STARTED.md)
2. **Run**: `python quickstart.py`
3. **Learn**: [EXAMPLES.md](EXAMPLES.md)
4. **Build**: Create your own workflow in `workflows/`
5. **Deploy**: Use Ray cluster with `--ray-address`

## Support & Documentation

- **Quick Start**: [START_HERE.md](START_HERE.md)
- **Getting Started**: [GETTING_STARTED.md](GETTING_STARTED.md)
- **API Reference**: [API_SIMPLIFIED.md](API_SIMPLIFIED.md)
- **Examples**: [EXAMPLES.md](EXAMPLES.md)
- **Architecture**: [solstice/README.md](solstice/README.md)
- **Full Index**: [INDEX.md](INDEX.md)

## Status

âœ… **COMPLETE AND READY FOR USE**

All requirements met:
- âœ… Import paths simplified (`from solstice.core...`)
- âœ… Documentation in English
- âœ… FlatMapOperator available
- âœ… Simplified parallelism API
- âœ… Complete examples and documentation

Start streaming now: `python quickstart.py` ğŸš€

