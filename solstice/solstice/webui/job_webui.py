# Copyright 2025 nurion team
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Job WebUI - per-job WebUI instance."""

import asyncio
from typing import TYPE_CHECKING

from solstice.webui.collectors.archiver import JobArchiver
from solstice.webui.collectors.exceptions import ExceptionAggregator
from solstice.webui.collectors.lineage import LineageTracker
from solstice.webui.collectors.metrics import MetricsCollector
from solstice.webui.storage import JobStorage
from solstice.utils.logging import create_ray_logger

if TYPE_CHECKING:
    from solstice.runtime.ray_runner import RayJobRunner


class JobWebUI:
    """WebUI instance for a single Solstice job.

    This component:
    1. Starts data collectors (metrics, lineage, exceptions)
    2. Archives job data when complete

    Job metadata (dag_edges, start_time) is stored in the payload_store actor
    by RayJobRunner, eliminating the need for a centralized registry.

    Not a Ray Serve deployment - runs as part of RayJobRunner.
    """

    def __init__(
        self,
        job_runner: "RayJobRunner",
        storage: JobStorage,
        attempt_id: str,
        prometheus_enabled: bool = True,
    ):
        """Initialize job WebUI.

        Args:
            job_runner: RayJobRunner instance
            storage: SlateDB storage instance
            attempt_id: Unique attempt ID for this run (required, generated by RayJobRunner)
            prometheus_enabled: Whether to export Prometheus metrics
        """
        self.job_runner = job_runner
        self.storage = storage
        self.job_id = job_runner.job.job_id
        self.attempt_id = attempt_id

        self.logger = create_ray_logger(f"JobWebUI-{self.job_id}")

        # Collectors
        self.metrics_collector = MetricsCollector(
            job_runner,
            storage,
            prometheus_enabled=prometheus_enabled,
        )
        self.lineage_tracker = LineageTracker(self.job_id, storage)
        self.exception_aggregator = ExceptionAggregator(self.job_id, storage)
        self.archiver = JobArchiver(storage)

        # Background tasks
        self._collector_tasks = []

        self.logger.info("Job WebUI initialized")

    async def start(self) -> None:
        """Start the WebUI components.

        Starts background collector tasks for metrics gathering.
        """
        # Start collectors
        self._collector_tasks.append(asyncio.create_task(self.metrics_collector.run_loop()))

        self.logger.info("Job WebUI started")

    async def stop(self) -> None:
        """Stop the WebUI components.

        - Stops collector tasks
        - Archives job data
        """
        self.logger.info("Stopping Job WebUI")

        # Stop collectors
        self.metrics_collector.stop()

        # Wait for tasks to complete
        for task in self._collector_tasks:
            if not task.done():
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass

        self._collector_tasks.clear()

        # Archive job (best effort - log if fails but don't crash)
        try:
            await self.archiver.archive_job(self.job_runner)
            self.logger.info("Job archived successfully")
        except Exception:
            self.logger.exception("Failed to archive job")
