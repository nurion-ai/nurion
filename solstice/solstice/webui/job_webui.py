# Copyright 2025 nurion team
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Job WebUI - per-job WebUI instance."""

import asyncio
import time
from typing import TYPE_CHECKING

import ray

from solstice.webui.collectors.archiver import JobArchiver
from solstice.webui.collectors.exceptions import ExceptionAggregator
from solstice.webui.collectors.lineage import LineageTracker
from solstice.webui.collectors.metrics import MetricsCollector
from solstice.webui.registry import JobRegistration, get_or_create_registry
from solstice.webui.storage import SlateDBStorage
from solstice.utils.logging import create_ray_logger

if TYPE_CHECKING:
    from solstice.runtime.ray_runner import RayJobRunner


class JobWebUI:
    """WebUI instance for a single Solstice job.

    This component:
    1. Registers the job with the global JobRegistry
    2. Starts data collectors (metrics, events, lineage, exceptions)
    3. Provides methods for the Portal to query job data
    4. Archives job data when complete

    Not a Ray Serve deployment - runs as part of RayJobRunner.
    """

    def __init__(
        self,
        job_runner: "RayJobRunner",
        storage: SlateDBStorage,
        attempt_id: str,
        prometheus_enabled: bool = True,
    ):
        """Initialize job WebUI.

        Args:
            job_runner: RayJobRunner instance
            storage: SlateDB storage instance
            attempt_id: Unique attempt ID for this run (required, generated by RayJobRunner)
            prometheus_enabled: Whether to export Prometheus metrics
        """
        self.job_runner = job_runner
        self.storage = storage
        self.job_id = job_runner.job.job_id
        self.attempt_id = attempt_id

        self.logger = create_ray_logger(f"JobWebUI-{self.job_id}")

        # Registry
        self.registry = get_or_create_registry()

        # Collectors
        self.metrics_collector = MetricsCollector(
            job_runner,
            storage,
            prometheus_enabled=prometheus_enabled,
        )
        self.lineage_tracker = LineageTracker(self.job_id, storage)
        self.exception_aggregator = ExceptionAggregator(self.job_id, storage)
        self.archiver = JobArchiver(storage)

        # Note: EventCollector is passive - it receives events via HTTP endpoint
        # No background task needed

        # Background tasks
        self._collector_tasks = []

        self.logger.info("Job WebUI initialized")

    async def start(self) -> None:
        """Start the WebUI components.

        - Registers job with global registry
        - Starts background collector tasks
        """
        # Register with global registry
        registration = JobRegistration(
            job_id=self.job_id,
            job_name=self.job_id,  # TODO: Support custom job names
            start_time=time.time(),
            status="INITIALIZING",
            stage_count=len(self.job_runner.job.stages),
            worker_count=0,
            runner_actor_name=f"jobwebui_{self.job_id}",
            attempt_id=self.attempt_id,
        )

        ray.get(self.registry.register.remote(self.job_id, registration))
        self.logger.info(f"Registered job {self.job_id} with global registry")

        # Start collectors
        self._collector_tasks.append(asyncio.create_task(self.metrics_collector.run_loop()))

        # EventCollector is passive (receives events via HTTP), no background task

        # Update status to RUNNING
        ray.get(self.registry.update.remote(self.job_id, {"status": "RUNNING"}))

        self.logger.info("Job WebUI started")

    async def stop(self) -> None:
        """Stop the WebUI components.

        - Stops collector tasks
        - Archives job data
        - Unregisters from registry
        """
        self.logger.info("Stopping Job WebUI")

        # Stop collectors
        self.metrics_collector.stop()

        # Wait for tasks to complete
        for task in self._collector_tasks:
            if not task.done():
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass

        self._collector_tasks.clear()

        # Archive job (best effort - log if fails but don't crash)
        try:
            await self.archiver.archive_job(self.job_runner)
            self.logger.info("Job archived successfully")
        except Exception:
            self.logger.exception("Failed to archive job")

        # Unregister from registry (best effort)
        try:
            ray.get(self.registry.unregister.remote(self.job_id), timeout=5)
            self.logger.info("Unregistered from global registry")
        except Exception:
            self.logger.exception("Failed to unregister from registry")

    def update_worker_count(self, count: int) -> None:
        """Update worker count in registry (best effort).

        Args:
            count: New worker count
        """
        try:
            ray.get(self.registry.update.remote(self.job_id, {"worker_count": count}), timeout=1)
        except Exception:
            # Non-critical update, silently ignore failures
            pass
